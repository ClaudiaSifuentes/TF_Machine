{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import Input\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(MAIN_DIR, 'data')\n",
    "MODEL_DIR = os.path.join(MAIN_DIR, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960300e+06</td>\n",
       "      <td>Dogecoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.509085e+06</td>\n",
       "      <td>Dogecoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169688e+06</td>\n",
       "      <td>Dogecoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.188943e+06</td>\n",
       "      <td>Dogecoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115034e+07</td>\n",
       "      <td>Dogecoin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Volume    Market Cap  \\\n",
       "0  2013-12-15  0.000559  0.000904  0.000290  0.000298     0.0  1.960300e+06   \n",
       "1  2013-12-16  0.000299  0.000866  0.000150  0.000205     0.0  1.509085e+06   \n",
       "2  2013-12-17  0.000207  0.000289  0.000116  0.000269     0.0  2.169688e+06   \n",
       "3  2013-12-18  0.000267  0.000362  0.000205  0.000362     0.0  3.188943e+06   \n",
       "4  2013-12-19  0.000395  0.001520  0.000328  0.001162     0.0  1.115034e+07   \n",
       "\n",
       "     Source  \n",
       "0  Dogecoin  \n",
       "1  Dogecoin  \n",
       "2  Dogecoin  \n",
       "3  Dogecoin  \n",
       "4  Dogecoin  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATA_DIR,'merged_data.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>high_low_diff</th>\n",
       "      <th>open_close_diff</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.509085e+06</td>\n",
       "      <td>1.387152e+09</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169688e+06</td>\n",
       "      <td>1.387238e+09</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.188943e+06</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115034e+07</td>\n",
       "      <td>1.387411e+09</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.284337e+06</td>\n",
       "      <td>1.387498e+09</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Volume    Market Cap     Timestamp  \\\n",
       "1  0.000299  0.000866  0.000150  0.000205     0.0  1.509085e+06  1.387152e+09   \n",
       "2  0.000207  0.000289  0.000116  0.000269     0.0  2.169688e+06  1.387238e+09   \n",
       "3  0.000267  0.000362  0.000205  0.000362     0.0  3.188943e+06  1.387325e+09   \n",
       "4  0.000395  0.001520  0.000328  0.001162     0.0  1.115034e+07  1.387411e+09   \n",
       "5  0.001143  0.001143  0.000662  0.000704     0.0  7.284337e+06  1.387498e+09   \n",
       "\n",
       "   high_low_diff  open_close_diff  target  \n",
       "1       0.000716        -0.000095       0  \n",
       "2       0.000173         0.000062       1  \n",
       "3       0.000157         0.000094       1  \n",
       "4       0.001191         0.000767       1  \n",
       "5       0.000481        -0.000439       0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Timestamp'] = data['Date'].apply(lambda x: x.timestamp())\n",
    "data['price_change'] = data.groupby('Source')['Close'].pct_change()\n",
    "data['high_low_diff'] = data['High'] - data['Low']\n",
    "data['open_close_diff'] = data['Close'] - data['Open']\n",
    "data.dropna(inplace=True);\n",
    "data['target'] = data['price_change'].apply(lambda x: 1 if x > 0 else 0)\n",
    "data.drop(['Date', 'Source', 'price_change'], axis=1, inplace=True)\n",
    "data.sort_values('Timestamp', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17658, 10)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Volume',\n",
       " 'Market Cap',\n",
       " 'Timestamp',\n",
       " 'high_low_diff',\n",
       " 'open_close_diff']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop('target', axis=1).columns\n",
    "features = list(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open               0\n",
      "High               0\n",
      "Low                0\n",
      "Close              0\n",
      "Volume             0\n",
      "Market Cap         0\n",
      "Timestamp          0\n",
      "high_low_diff      0\n",
      "open_close_diff    0\n",
      "target             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.drop('target')\n",
    "data[numeric_cols] = data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data[features].values)\n",
    "y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Capa de entrada con la forma de X_train.\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    # Capa densa con 128 unidades, activación ReLU y regularización L2 (0.01).\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    # Capa de normalización por lotes para normalizar las activaciones de la capa anterior.\n",
    "    BatchNormalization(),\n",
    "    # Capa de Dropout con una tasa de abandono del 0.3 para prevenir el sobreajuste.\n",
    "    Dropout(0.3),\n",
    "    # Capa densa con 64 unidades, activación ReLU y regularización L2 (0.01).\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    # Capa de normalización por lotes para normalizar las activaciones de la capa anterior.\n",
    "    BatchNormalization(),\n",
    "    # Capa de Dropout con una tasa de abandono del 0.3 para prevenir el sobreajuste.\n",
    "    Dropout(0.3),\n",
    "    # Capa densa con 32 unidades y activación ReLU.\n",
    "    Dense(32, activation='relu'),\n",
    "    # Capa densa con 1 unidad y activación sigmoide para la salida de clasificación binaria.\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 1.5052 - val_accuracy: 0.5071 - val_loss: 0.9912 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5204 - loss: 0.9354 - val_accuracy: 0.4947 - val_loss: 0.8174 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5378 - loss: 0.7745 - val_accuracy: 0.4961 - val_loss: 0.7446 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5635 - loss: 0.7142 - val_accuracy: 0.5042 - val_loss: 0.8507 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.6854 - val_accuracy: 0.6277 - val_loss: 0.6647 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.6626 - val_accuracy: 0.5336 - val_loss: 0.7571 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 0.6345 - val_accuracy: 0.5655 - val_loss: 0.6632 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6333 - loss: 0.6222 - val_accuracy: 0.6086 - val_loss: 0.6168 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6405 - loss: 0.6163 - val_accuracy: 0.5842 - val_loss: 0.6302 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6298 - loss: 0.6273 - val_accuracy: 0.5757 - val_loss: 0.6738 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.6039 - val_accuracy: 0.5743 - val_loss: 0.6354 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6646 - loss: 0.5970 - val_accuracy: 0.7222 - val_loss: 0.5953 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6711 - loss: 0.5893 - val_accuracy: 0.6065 - val_loss: 0.6105 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6678 - loss: 0.5858 - val_accuracy: 0.6561 - val_loss: 0.5849 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6692 - loss: 0.5827 - val_accuracy: 0.7219 - val_loss: 0.5762 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6659 - loss: 0.5854 - val_accuracy: 0.6196 - val_loss: 0.5914 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.5693 - val_accuracy: 0.6610 - val_loss: 0.5783 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6701 - loss: 0.5739 - val_accuracy: 0.5980 - val_loss: 0.6149 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6832 - loss: 0.5607 - val_accuracy: 0.6352 - val_loss: 0.5628 - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6797 - loss: 0.5618 - val_accuracy: 0.7240 - val_loss: 0.5469 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.5629 - val_accuracy: 0.8114 - val_loss: 0.5631 - learning_rate: 2.5000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6847 - loss: 0.5590 - val_accuracy: 0.6504 - val_loss: 0.5693 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6816 - loss: 0.5567 - val_accuracy: 0.8259 - val_loss: 0.5789 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.5521 - val_accuracy: 0.8500 - val_loss: 0.5501 - learning_rate: 1.2500e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6854 - loss: 0.5547 - val_accuracy: 0.6737 - val_loss: 0.5471 - learning_rate: 1.2500e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6818 - loss: 0.5623 - val_accuracy: 0.6341 - val_loss: 0.5699 - learning_rate: 1.2500e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6857 - loss: 0.5495 - val_accuracy: 0.7074 - val_loss: 0.5475 - learning_rate: 6.2500e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.5445 - val_accuracy: 0.8705 - val_loss: 0.5398 - learning_rate: 6.2500e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.5400 - val_accuracy: 0.6967 - val_loss: 0.5372 - learning_rate: 6.2500e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.5428 - val_accuracy: 0.7463 - val_loss: 0.5374 - learning_rate: 6.2500e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.5402 - val_accuracy: 0.8715 - val_loss: 0.5444 - learning_rate: 6.2500e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6897 - loss: 0.5388 - val_accuracy: 0.8252 - val_loss: 0.5314 - learning_rate: 6.2500e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.5376 - val_accuracy: 0.6982 - val_loss: 0.5443 - learning_rate: 6.2500e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6923 - loss: 0.5414 - val_accuracy: 0.8443 - val_loss: 0.5412 - learning_rate: 6.2500e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.5330 - val_accuracy: 0.8135 - val_loss: 0.5208 - learning_rate: 6.2500e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 0.5340 - val_accuracy: 0.7406 - val_loss: 0.5362 - learning_rate: 6.2500e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.5390 - val_accuracy: 0.8171 - val_loss: 0.5375 - learning_rate: 6.2500e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.5345 - val_accuracy: 0.7208 - val_loss: 0.5412 - learning_rate: 6.2500e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7022 - loss: 0.5324 - val_accuracy: 0.8167 - val_loss: 0.5383 - learning_rate: 3.1250e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.5279 - val_accuracy: 0.8475 - val_loss: 0.5226 - learning_rate: 3.1250e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.5335 - val_accuracy: 0.8496 - val_loss: 0.5221 - learning_rate: 3.1250e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7128 - loss: 0.5312 - val_accuracy: 0.8493 - val_loss: 0.5307 - learning_rate: 1.5625e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7091 - loss: 0.5292 - val_accuracy: 0.7148 - val_loss: 0.5434 - learning_rate: 1.5625e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 0.5335 - val_accuracy: 0.8344 - val_loss: 0.5304 - learning_rate: 1.5625e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.5243 - val_accuracy: 0.7127 - val_loss: 0.5502 - learning_rate: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79      1915\n",
      "           1       0.72      0.89      0.80      1617\n",
      "\n",
      "    accuracy                           0.79      3532\n",
      "   macro avg       0.80      0.80      0.79      3532\n",
      "weighted avg       0.81      0.79      0.79      3532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODEL_DIR, 'model.keras'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
