# ğŸ¤– ComparaciÃ³n de Modelos de Deep Learning

Este proyecto evalÃºa diferentes arquitecturas de redes neuronales (MLP, GRU y Bidirectional LSTM) para resolver una **tarea de clasificaciÃ³n binaria**.  
Se implementa un pipeline completo de *entrenamiento, evaluaciÃ³n y despliegue* con interfaz web y API.

---

## ğŸ“‚ Estructura del proyecto

```

TF_Machine-main/
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ api/                 # API REST con FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ source/process.py
â”‚   â”œâ”€â”€ app/                 # AplicaciÃ³n web (frontend)
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ public/          # ImÃ¡genes de resultados
â”‚   â””â”€â”€ notebooks/           # Notebooks de entrenamiento y EDA
â”‚       â”œâ”€â”€ eda.ipynb
â”‚       â””â”€â”€ training.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ merged_data.csv
â”‚   â””â”€â”€ response_data.csv
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.keras          # Modelo entrenado
â”‚
â”œâ”€â”€ results.md               # MÃ©tricas detalladas de cada modelo
â””â”€â”€ README.md

````

---

## âš™ï¸ Requisitos

- **Python 3.10+**
- LibrerÃ­as principales:
  ```bash
  pip install tensorflow scikit-learn pandas numpy matplotlib seaborn fastapi uvicorn
  ````

---

## ğŸš€ EjecuciÃ³n

### 1. AnÃ¡lisis exploratorio (EDA)

Abre y ejecuta el notebook:

```bash
notebooks/eda.ipynb
```

Analiza correlaciones y limpieza del dataset (`merged_data.csv`).

### 2. Entrenamiento de modelos

```bash
notebooks/training.ipynb
```

Entrena los modelos **MLP**, **GRU** y **Bidirectional LSTM** y guarda los resultados en `results.md`.

### 3. API con FastAPI

Desde `/code/api/`:

```bash
uvicorn main:app --reload
```

Endpoint principal:

* `POST /predict` â†’ recibe datos de entrada y devuelve la clase predicha.

### 4. VisualizaciÃ³n

Abre `code/app/index.html` en tu navegador para ver el panel de resultados y predicciones.

---

## ğŸ§  Modelos evaluados

| Modelo      | Exactitud | Comentario                                          |
| ----------- | --------- | --------------------------------------------------- |
| **MLP**     | 0.74      | Mejor rendimiento general, balanceado entre clases. |
| **GRU**     | 0.51      | Bajo desempeÃ±o, recall alto solo para una clase.    |
| **Bi-LSTM** | 0.50      | Sesgo hacia la clase 1, rendimiento desigual.       |

> ğŸ“ˆ El MLP fue el modelo mÃ¡s estable, logrando F1-score promedio de **0.74**.

---

## ğŸ“Š Resultados destacados

* **MLP:** Mejor balance entre precisiÃ³n y recall.
* **GRU:** Detecta mejor la clase positiva pero con menor exactitud global.
* **Bidirectional LSTM:** Sobresaturado hacia una clase, requiere reentrenamiento o regularizaciÃ³n.

---

## ğŸ PrÃ³ximos pasos

* Integrar almacenamiento en cloud (S3 o Firestore).
* Optimizar hiperparÃ¡metros del MLP.
* Desplegar API en un entorno serverless (AWS Lambda / Render).

```


